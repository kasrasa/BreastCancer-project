{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model for BreastCancer Calssification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import SeparableConv2D,Dense,MaxPool2D,BatchNormalization,Activation,Flatten,Dropout\n",
    "from keras import backend as k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Cancer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a model class that takes the size and depth of the image along with the number of classes\n",
    "# which in this project is 2 \n",
    "class Cancer:\n",
    "    @staticmethod\n",
    "    def build(width,height,depth,classes):\n",
    "\n",
    "        model = Sequential()\n",
    "        input_shape = (height,width,depth)\n",
    "        channel_dim = -1\n",
    "\n",
    "        if k.image_data_format()==\"channels_first\": # in case the format of the image is reversed\n",
    "            input_shape=(depth,height,width)\n",
    "            channel_dim = 1\n",
    "                \n",
    "\n",
    "        model.add(SeparableConv2D(32,(3,3),input_shape = input_shape,padding = \"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis = channel_dim))\n",
    "        model.add(MaxPool2D((2,2)))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(SeparableConv2D(64,(3,3),padding = \"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis = channel_dim))\n",
    "        model.add(SeparableConv2D(64,(3,3),padding = \"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis = channel_dim))\n",
    "        model.add(MaxPool2D((2,2)))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(SeparableConv2D(128,(3,3),padding = \"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis = channel_dim))\n",
    "        model.add(SeparableConv2D(128,(3,3),padding = \"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis = channel_dim))\n",
    "        model.add(SeparableConv2D(128,(3,3),padding = \"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis = channel_dim))\n",
    "        model.add(MaxPool2D((2,2)))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(256))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis = channel_dim))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.optimizers import Adagrad,Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import config\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 255815 images belonging to 2 classes.\n",
      "Found 42660 images belonging to 2 classes.\n",
      "Found 99906 images belonging to 2 classes.\n",
      "Epoch 1/40\n",
      "7994/7994 [==============================] - 2708s 339ms/step - loss: 0.5992 - accuracy: 0.8193 - val_loss: 0.6126 - val_accuracy: 0.7499\n",
      "Epoch 2/40\n",
      "7994/7994 [==============================] - 1280s 160ms/step - loss: 0.5620 - accuracy: 0.8304 - val_loss: 0.6964 - val_accuracy: 0.7037\n",
      "Epoch 3/40\n",
      "7994/7994 [==============================] - 695s 87ms/step - loss: 0.5541 - accuracy: 0.8339 - val_loss: 0.5980 - val_accuracy: 0.7510\n",
      "Epoch 4/40\n",
      "7994/7994 [==============================] - 641s 80ms/step - loss: 0.5498 - accuracy: 0.8354 - val_loss: 0.5624 - val_accuracy: 0.7715\n",
      "Epoch 5/40\n",
      "7994/7994 [==============================] - 630s 79ms/step - loss: 0.5464 - accuracy: 0.8356 - val_loss: 0.5592 - val_accuracy: 0.7744\n",
      "Epoch 6/40\n",
      "7994/7994 [==============================] - 631s 79ms/step - loss: 0.5460 - accuracy: 0.8361 - val_loss: 0.5507 - val_accuracy: 0.7774\n",
      "Epoch 7/40\n",
      "7994/7994 [==============================] - 627s 78ms/step - loss: 0.5444 - accuracy: 0.8371 - val_loss: 0.5557 - val_accuracy: 0.7754\n",
      "Epoch 8/40\n",
      "7994/7994 [==============================] - 669s 84ms/step - loss: 0.5439 - accuracy: 0.8365 - val_loss: 0.5504 - val_accuracy: 0.7769\n",
      "Epoch 9/40\n",
      "7994/7994 [==============================] - 728s 91ms/step - loss: 0.5438 - accuracy: 0.8365 - val_loss: 0.5394 - val_accuracy: 0.7812\n",
      "Epoch 10/40\n",
      "7994/7994 [==============================] - 642s 80ms/step - loss: 0.5422 - accuracy: 0.8370 - val_loss: 0.5361 - val_accuracy: 0.7827\n",
      "Epoch 11/40\n",
      "7994/7994 [==============================] - 655s 82ms/step - loss: 0.5421 - accuracy: 0.8372 - val_loss: 0.5364 - val_accuracy: 0.7837\n",
      "Epoch 12/40\n",
      "7994/7994 [==============================] - 622s 78ms/step - loss: 0.5403 - accuracy: 0.8375 - val_loss: 0.5346 - val_accuracy: 0.7850\n",
      "Epoch 13/40\n",
      "7994/7994 [==============================] - 616s 77ms/step - loss: 0.5397 - accuracy: 0.8383 - val_loss: 0.5334 - val_accuracy: 0.7856\n",
      "Epoch 14/40\n",
      "7994/7994 [==============================] - 617s 77ms/step - loss: 0.5398 - accuracy: 0.8386 - val_loss: 0.5196 - val_accuracy: 0.7909\n",
      "Epoch 15/40\n",
      "7994/7994 [==============================] - 620s 78ms/step - loss: 0.5397 - accuracy: 0.8382 - val_loss: 0.5305 - val_accuracy: 0.7873\n",
      "Epoch 16/40\n",
      "7994/7994 [==============================] - 623s 78ms/step - loss: 0.5402 - accuracy: 0.8382 - val_loss: 0.5326 - val_accuracy: 0.7857\n",
      "Epoch 17/40\n",
      "7994/7994 [==============================] - 633s 79ms/step - loss: 0.5394 - accuracy: 0.8377 - val_loss: 0.5210 - val_accuracy: 0.7885\n",
      "Epoch 18/40\n",
      "7994/7994 [==============================] - 627s 78ms/step - loss: 0.5382 - accuracy: 0.8390 - val_loss: 0.5145 - val_accuracy: 0.7941\n",
      "Epoch 19/40\n",
      "7994/7994 [==============================] - 617s 77ms/step - loss: 0.5390 - accuracy: 0.8391 - val_loss: 0.5237 - val_accuracy: 0.7890\n",
      "Epoch 20/40\n",
      "7994/7994 [==============================] - 616s 77ms/step - loss: 0.5379 - accuracy: 0.8393 - val_loss: 0.5108 - val_accuracy: 0.7948\n",
      "Epoch 21/40\n",
      "7994/7994 [==============================] - 620s 78ms/step - loss: 0.5374 - accuracy: 0.8389 - val_loss: 0.5133 - val_accuracy: 0.7945\n",
      "Epoch 22/40\n",
      "7994/7994 [==============================] - 623s 78ms/step - loss: 0.5374 - accuracy: 0.8388 - val_loss: 0.5189 - val_accuracy: 0.7921\n",
      "Epoch 23/40\n",
      "7994/7994 [==============================] - 624s 78ms/step - loss: 0.5389 - accuracy: 0.8395 - val_loss: 0.5130 - val_accuracy: 0.7943\n",
      "Epoch 24/40\n",
      "7994/7994 [==============================] - 625s 78ms/step - loss: 0.5375 - accuracy: 0.8391 - val_loss: 0.5179 - val_accuracy: 0.7922\n",
      "Epoch 25/40\n",
      "7994/7994 [==============================] - 620s 78ms/step - loss: 0.5377 - accuracy: 0.8388 - val_loss: 0.5175 - val_accuracy: 0.7936\n",
      "Epoch 26/40\n",
      "7994/7994 [==============================] - 616s 77ms/step - loss: 0.5370 - accuracy: 0.8391 - val_loss: 0.5081 - val_accuracy: 0.7968\n",
      "Epoch 27/40\n",
      "7994/7994 [==============================] - 619s 77ms/step - loss: 0.5379 - accuracy: 0.8388 - val_loss: 0.5118 - val_accuracy: 0.7952\n",
      "Epoch 28/40\n",
      "7994/7994 [==============================] - 48094s 6s/step - loss: 0.5384 - accuracy: 0.8386 - val_loss: 0.5183 - val_accuracy: 0.7919\n",
      "Epoch 29/40\n",
      "7994/7994 [==============================] - 4155s 520ms/step - loss: 0.5365 - accuracy: 0.8393 - val_loss: 0.5141 - val_accuracy: 0.7940\n",
      "Epoch 30/40\n",
      "7994/7994 [==============================] - 660s 83ms/step - loss: 0.5377 - accuracy: 0.8388 - val_loss: 0.5100 - val_accuracy: 0.7952\n",
      "Epoch 31/40\n",
      "7994/7994 [==============================] - 624s 78ms/step - loss: 0.5355 - accuracy: 0.8389 - val_loss: 0.5205 - val_accuracy: 0.7920\n",
      "Epoch 32/40\n",
      "7994/7994 [==============================] - 617s 77ms/step - loss: 0.5373 - accuracy: 0.8388 - val_loss: 0.5073 - val_accuracy: 0.7973\n",
      "Epoch 33/40\n",
      "7994/7994 [==============================] - 641s 80ms/step - loss: 0.5368 - accuracy: 0.8395 - val_loss: 0.5078 - val_accuracy: 0.7970\n",
      "Epoch 34/40\n",
      "7994/7994 [==============================] - 620s 78ms/step - loss: 0.5366 - accuracy: 0.8388 - val_loss: 0.5141 - val_accuracy: 0.7942\n",
      "Epoch 35/40\n",
      "7994/7994 [==============================] - 651s 81ms/step - loss: 0.5348 - accuracy: 0.8398 - val_loss: 0.5114 - val_accuracy: 0.7956\n",
      "Epoch 36/40\n",
      "7994/7994 [==============================] - 657s 82ms/step - loss: 0.5366 - accuracy: 0.8391 - val_loss: 0.5109 - val_accuracy: 0.7966\n",
      "Epoch 37/40\n",
      "7994/7994 [==============================] - 649s 81ms/step - loss: 0.5365 - accuracy: 0.8393 - val_loss: 0.5157 - val_accuracy: 0.7935\n",
      "Epoch 38/40\n",
      "7994/7994 [==============================] - 637s 80ms/step - loss: 0.5365 - accuracy: 0.8386 - val_loss: 0.4997 - val_accuracy: 0.7998\n",
      "Epoch 39/40\n",
      "7994/7994 [==============================] - 639s 80ms/step - loss: 0.5349 - accuracy: 0.8395 - val_loss: 0.5024 - val_accuracy: 0.7998\n",
      "Epoch 40/40\n",
      "7994/7994 [==============================] - 634s 79ms/step - loss: 0.5363 - accuracy: 0.8396 - val_loss: 0.5139 - val_accuracy: 0.7950\n",
      "Evaluating the model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.75      0.84     71451\n",
      "           1       0.59      0.92      0.72     28455\n",
      "\n",
      "    accuracy                           0.80     99906\n",
      "   macro avg       0.77      0.83      0.78     99906\n",
      "weighted avg       0.85      0.80      0.80     99906\n",
      "\n",
      "[[53392 18059]\n",
      " [ 2418 26037]]\n",
      "Accuracy: 0.7950373350949893\n",
      "Precision: 0.9566744311055366\n",
      "Recall: 0.7472533624441925\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 40\n",
    "lr = 1e-2\n",
    "bs = 32\n",
    "\n",
    "# importing the data paths\n",
    "trainPaths=list(paths.list_images(config.Train_path))\n",
    "lenTrain=len(trainPaths)\n",
    "lenVal=len(list(paths.list_images(config.Val_path)))\n",
    "lenTest=len(list(paths.list_images(config.Test_path)))\n",
    "\n",
    "\n",
    "trainLabels=[int(p.split(os.path.sep)[-2]) for p in trainPaths]\n",
    "trainLabels=np_utils.to_categorical(trainLabels)\n",
    "classTotals=trainLabels.sum(axis=0)\n",
    "classWeight=dict(enumerate(classTotals.max()/classTotals))\n",
    "\n",
    "\n",
    "# augmenting the train data\n",
    "TrainAug = ImageDataGenerator(rescale=1/255.0,shear_range=0.05,rotation_range=10,width_shift_range=0.01,\n",
    "                              height_shift_range=0.01,zoom_range=0.05,horizontal_flip=True,vertical_flip=True\n",
    "                             ,fill_mode=\"nearest\")\n",
    "\n",
    "# Normalizing the validation data (it will be used for test data as well)\n",
    "ValAug = ImageDataGenerator(rescale = 1/255.0)\n",
    "\n",
    "TrainAugmented = TrainAug.flow_from_directory(directory = config.Train_path,\n",
    "                                              class_mode=\"categorical\",\n",
    "                                              target_size=(48,48),\n",
    "                                              color_mode=\"rgb\",\n",
    "                                              shuffle=True,\n",
    "                                              batch_size=bs)\n",
    "ValAugmented = ValAug.flow_from_directory(directory = config.Val_path,\n",
    "                                              class_mode=\"categorical\",\n",
    "                                              target_size=(48,48),\n",
    "                                              color_mode=\"rgb\",\n",
    "                                              shuffle=False,\n",
    "                                              batch_size=bs)\n",
    "TestAugmented = ValAug.flow_from_directory(directory = config.Test_path,\n",
    "                                              class_mode=\"categorical\",\n",
    "                                              target_size=(48,48),\n",
    "                                              color_mode=\"rgb\",\n",
    "                                              shuffle=False,\n",
    "                                              batch_size=bs)\n",
    "\n",
    "optimizers = [Adagrad(learning_rate=lr,decay = lr/num_epochs)]#Adam(learning_rate=lr,decay = lr/num_epochs),\n",
    "for opt in optimizers:\n",
    "#     if opt == optimizers[0]:\n",
    "#         opt_name = \"adam\"\n",
    "#     else:\n",
    "#         opt_name = \"adagrad\"\n",
    "        \n",
    "\n",
    "    model = Cancer.build(height = 48,width = 48,depth = 3,classes = 2)\n",
    "    model.compile(loss = \"binary_crossentropy\",optimizer = opt,metrics = [\"accuracy\"])\n",
    "\n",
    "    M=model.fit(TrainAugmented,\n",
    "                steps_per_epoch=lenTrain//bs,\n",
    "                validation_data=ValAugmented,\n",
    "                validation_steps=lenVal//bs,\n",
    "                class_weight=classWeight,\n",
    "                epochs=num_epochs)\n",
    "\n",
    "    print(\"Evaluating the model\")\n",
    "    TestAugmented.reset()\n",
    "    pred_indices = model.predict(TestAugmented,steps=(lenTest//bs)+1,verbose=1)\n",
    "    pred_indices=np.argmax(pred_indices,axis=1)\n",
    "\n",
    "    print(classification_report(TestAugmented.classes, pred_indices, target_names=TestAugmented.class_indices.keys()))\n",
    "\n",
    "    confusion = confusion_matrix(TestAugmented.classes,pred_indices)\n",
    "    total=sum(sum(confusion))\n",
    "    accuracy=(confusion[0,0]+confusion[1,1])/total\n",
    "    precision=confusion[0,0]/(confusion[0,0]+confusion[1,0])\n",
    "    recall=confusion[0,0]/(confusion[0,0]+confusion[0,1])\n",
    "    print(confusion)\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    \n",
    "    N = num_epochs\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(0,N), M.history[\"loss\"], label=\"train_loss\")\n",
    "    plt.plot(np.arange(0,N), M.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.title(f\"Training and Validation Loss on the IDC Dataset using {opt_name}\")\n",
    "    plt.xlabel(\"Epoch No.\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.savefig('plot.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model\n",
      "3123/3123 [==============================] - 359s 115ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.79      0.87     71451\n",
      "           1       0.64      0.94      0.76     28455\n",
      "\n",
      "    accuracy                           0.83     99906\n",
      "   macro avg       0.81      0.87      0.82     99906\n",
      "weighted avg       0.88      0.83      0.84     99906\n",
      "\n",
      "[[56387 15064]\n",
      " [ 1639 26816]]\n",
      "Accuracy: 0.832812844073429\n",
      "Precision: 0.9717540412918347\n",
      "Recall: 0.7891702005570251\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating the model\")\n",
    "TestAugmented.reset()\n",
    "pred_indices = model.predict(TestAugmented,steps=(lenTest//bs)+1,verbose=1)\n",
    "pred_indices=np.argmax(pred_indices,axis=1)\n",
    "\n",
    "print(classification_report(TestAugmented.classes, pred_indices, target_names=TestAugmented.class_indices.keys()))\n",
    "\n",
    "confusion = confusion_matrix(TestAugmented.classes,pred_indices)\n",
    "total=sum(sum(confusion))\n",
    "accuracy=(confusion[0,0]+confusion[1,1])/total\n",
    "precision=confusion[0,0]/(confusion[0,0]+confusion[1,0])\n",
    "recall=confusion[0,0]/(confusion[0,0]+confusion[0,1])\n",
    "print(confusion)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "\n",
    "N = num_epochs\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0,N), M.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0,N), M.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.title(\"Training and Validation Loss on the IDC Dataset using adam\")\n",
    "plt.xlabel(\"Epoch No.\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig('plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
